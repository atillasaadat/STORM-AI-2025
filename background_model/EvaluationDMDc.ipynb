{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15YXsBIWY_Wh",
   "metadata": {},
   "source": [
    "# Install & import libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "UEEuRw7Cxuuy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os              : Windows-10-10.0.19045-SP0\n",
      "python          : 3.11.4\n",
      "tsai            : 0.3.9\n",
      "fastai          : 2.7.17\n",
      "fastcore        : 1.7.20\n",
      "sklearn         : 1.3.2\n",
      "torch           : 2.2.2+cpu\n",
      "device          : cpu\n",
      "cpu cores       : 16\n",
      "threads per cpu : 1\n",
      "RAM             : 31.75 GB\n",
      "GPU memory      : [23.99] GB\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from tsai.basics import *\n",
    "my_setup(sklearn)\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd\n",
    "import mat73\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.linalg import pinv\n",
    "from scipy.linalg import logm\n",
    "import pandas as pd\n",
    "\n",
    "from tsai.optuna import *\n",
    "import papermill as pm\n",
    "from tsai.optuna import run_optuna_study\n",
    "from fastcore.basics import *\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c95c7b0-62de-48da-ac06-0a5b3299a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPUs\n",
    "# Change the CUDA_VISIBLE_DEVICES values to numbers\n",
    "# See (https://forums.fast.ai/t/exception-occured-in-lrfinder-when-calling-event-after-fit/104389/8)\n",
    "if torch.cuda.is_available():\n",
    "    result = subprocess.check_output(\"nvidia-smi -L | grep -oE '[0-9]+:' | tr -d ':'\", shell=True).decode(\"utf-8\").strip()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = result\n",
    "\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a620ad3-3a50-46d8-8874-8ecc2adf180b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61721f2d-a8fb-485b-a98b-c77897e1e095",
   "metadata": {},
   "source": [
    "# Model and Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77af3910-4600-4544-be79-7e573ad8bc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a data set:\n",
      "1. NRLMSISE\n",
      "2. TIEGCM\n"
     ]
    }
   ],
   "source": [
    "# Define the available options\n",
    "data_options = [\"NRLMSISE\", \"TIEGCM\"]\n",
    "\n",
    "# Ask the user to select a data set\n",
    "print(\"Please select a data set:\")\n",
    "for i, option in enumerate(data_options, 1):\n",
    "    print(f\"{i}. {option}\")\n",
    "#data_choice = int(input(\"Enter the number of your choice: \"))\n",
    "data_choice = 1\n",
    "data_name = data_options[data_choice - 1]\n",
    "\n",
    "# Use the data_name in your naming path\n",
    "path = f\"data/{data_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658e2b0-4e10-44b8-957d-a2ff264df45c",
   "metadata": {},
   "source": [
    "#### Choose Training, Validation, and Test Density Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f68a7d15-e55c-4347-adcd-0b08b978f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRLMSISE\n",
    "if data_name == 'NRLMSISE':\n",
    "    df_raw = loadmat('data/Atmospheric Density ROMs/NRLMSISE_1997_2008_ROM_r100.mat')\n",
    "\n",
    "# TIEGCM\n",
    "if data_name == 'TIEGCM':\n",
    "    df_raw = scipy.io.loadmat('data/Atmospheric Density ROMs/ROM/TIEGCM_1997_2008_ROM_r100.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2be20c-04f6-421a-a18f-2c8dc5edbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD Dimension\n",
    "r=10\n",
    "\n",
    "# Atmospheric Density Snapshots\n",
    "X = df_raw[\"densityDataLogVarROM100\"][:r,:];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6663625f-6358-45d1-b182-18776db32367",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dee32de-6072-4e2d-93ab-d97d0279e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "freq = '1H'\n",
    "\n",
    "fcst_history = 24*3*6 # 1/freq*18 (18 days) 432 steps in the past\n",
    "fcst_horizon = 24*3  # 1/freq*3 (3 days) 72 steps in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4523888-9997-4975-9811-b3ffeff14817",
   "metadata": {},
   "source": [
    "#### Load Dataset and Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fb4cf4-4c8d-4f50-b0ad-fa138ac34c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "# Load dataframes\n",
    "low_df = load_object('training/training_data/low_df_'+path+'.pkl')\n",
    "low_df = low_df.reset_index(drop=True)\n",
    "\n",
    "medium_df = load_object('training/training_data/medium_df_'+path+'.pkl')\n",
    "medium_df = medium_df.reset_index(drop=True)\n",
    "\n",
    "high_df = load_object('training/training_data/high_df_'+path+'.pkl')\n",
    "high_df = high_df.reset_index(drop=True)\n",
    "\n",
    "# Load splits\n",
    "low_splits = load_object('training/splits/splits_lowSW_'+path+'.pkl')\n",
    "medium_splits = load_object('training/splits/splits_mediumSW_'+path+'.pkl')\n",
    "high_splits = load_object('training/splits/splits_highSW_'+path+'.pkl')\n",
    "\n",
    "# Low SW\n",
    "train_split = low_splits[0]\n",
    "exp_pipe = load_object('training/exp_pipe/exp_pipe_lowSW_'+path+'.pkl')\n",
    "low_df_scaled = exp_pipe.fit_transform(low_df, scaler__idxs=train_split)\n",
    "\n",
    "# Medium SW\n",
    "train_split = medium_splits[0]\n",
    "exp_pipe = load_object('training/exp_pipe/exp_pipe_mediumSW_'+path+'.pkl')\n",
    "medium_df_scaled = exp_pipe.fit_transform(medium_df, scaler__idxs=train_split)\n",
    "\n",
    "# High SW\n",
    "train_split = high_splits[0]\n",
    "exp_pipe = load_object('training/exp_pipe/exp_pipe_highSW_'+path+'.pkl')\n",
    "high_df_scaled = exp_pipe.fit_transform(high_df, scaler__idxs=train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8aab2e-b74f-4f31-bad8-6c91915d54e5",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f8e769f-b065-4502-a5f1-382b2eb22e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a data set:\n",
      "1. low space weather\n",
      "2. medium space weather\n",
      "3. high space weather\n"
     ]
    }
   ],
   "source": [
    "# Define the available options\n",
    "data_options = [\"low space weather\", \"medium space weather\", \"high space weather\"]\n",
    "\n",
    "# Ask the user to select a data set\n",
    "print(\"Please select a data set:\")\n",
    "for i, option in enumerate(data_options, 1):\n",
    "    print(f\"{i}. {option}\")\n",
    "data_choice = int(input(\"Enter the number of your choice: \"))\n",
    "training_name = data_options[data_choice - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ac7d00-fbb1-4722-a394-209d92cd6b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.1s\n"
     ]
    }
   ],
   "source": [
    "if training_name == 'low space weather':\n",
    "    # Low SW\n",
    "    columns = low_df.columns[1:]\n",
    "    train_split = low_splits[2]\n",
    "    exp_pipe = load_object('training/exp_pipe/exp_pipe_lowSW_'+path+'.pkl')\n",
    "    combined_df_test =  np.array(exp_pipe.fit_transform(low_df, scaler__idxs=train_split))\n",
    "elif training_name == 'medium space weather':\n",
    "    # Medium SW\n",
    "    columns = medium_df.columns[1:]\n",
    "    train_split = medium_splits[2]\n",
    "    exp_pipe = load_object('training/exp_pipe/exp_pipe_mediumSW_'+path+'.pkl')\n",
    "    combined_df_test =  np.array(exp_pipe.fit_transform(medium_df, scaler__idxs=train_split))\n",
    "elif training_name == 'high space weather':\n",
    "    # High SW\n",
    "    columns = high_df.columns[1:]\n",
    "    train_split = high_splits[2]\n",
    "    exp_pipe = load_object('training/exp_pipe/exp_pipe_highSW_'+path+'.pkl')\n",
    "    combined_df_test =  np.array(exp_pipe.fit_transform(high_df, scaler__idxs=train_split))\n",
    "else:\n",
    "    print(\"Name not recognized\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab79fef-db05-40e0-8493-dbdfbee46691",
   "metadata": {},
   "source": [
    "# Evaluate model üïµÔ∏è‚Äç‚ôÄÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b23bf6-4764-4c8b-b791-27e24c25853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U1 = combined_df_test[:-1,11:]\n",
    "\n",
    "X1 = combined_df_test[:-1,1:]\n",
    "X2 = combined_df_test[1:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb339f4e-7425-4fa0-b2b7-a10e4d363d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 = A*X1 + B*U1 = [A B]*[X1;U1] = Phi*Om\n",
    "Om = X1\n",
    "Om_numeric = Om.T.astype(np.float64)\n",
    "\n",
    "# Phi = X2*pinv(Om)\n",
    "Phi = np.dot(X2.T, np.linalg.pinv(Om_numeric))\n",
    "\n",
    "# Revert to just density\n",
    "X1 = combined_df_test[:-1, 1:r+1]\n",
    "X2 = combined_df_test[1:, 1:r+1]\n",
    "\n",
    "# Discrete-time dynamic and input matrix\n",
    "q = np.size(U1,1);\n",
    "\n",
    "A = Phi[:r, :r]\n",
    "B = Phi[:r, r:]\n",
    "\n",
    "dth = round(1/float(freq[:-1]))    # discrete time dt of the ROM in hours\n",
    "AB = np.concatenate((A, B), axis=1)\n",
    "zeros_eye = np.concatenate((np.zeros((q, r)), np.eye(q)), axis=1)\n",
    "\n",
    "Phi = np.concatenate((AB, zeros_eye), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "617b454e-3271-4ea0-86aa-189fd62d81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Covariance\n",
    "X2Pred = []\n",
    "errPred = []\n",
    "Qrom = []\n",
    "mse = []\n",
    "mae = []\n",
    "\n",
    "X2Pred.append(np.dot(A, X1[0].T) + np.dot(B, U1[0].T))  # Predict ROM state for 1hr\n",
    "errPred.append(X2Pred[0] - X2[0].T)  # Error of prediction w.r.t. training data\n",
    "# Calculate MSE\n",
    "mse.append(mean_squared_error(X2[0].T, X2Pred[0]))\n",
    "# Calculate MAE\n",
    "mae.append(mean_absolute_error(X2[0].T, X2Pred[0]))\n",
    "Qrom.append(np.cov(errPred[0].astype(float)))  # Covariance of error\n",
    "idx = [0]\n",
    "\n",
    "for i in range(fcst_horizon):\n",
    "    X2Pred.append(np.dot(A, X2Pred[i].T) + np.dot(B, U1[i].T))  # Predict ROM state for 1hr\n",
    "    errPred.append(X2Pred[i+1] - X2[i+1].T)  # Error of prediction w.r.t. training data\n",
    "    # Calculate MSE\n",
    "    mse.append(mean_squared_error(X2[i+1].T, X2Pred[i+1]))\n",
    "    # Calculate MAE\n",
    "    mae.append(mean_absolute_error(X2[i+1].T, X2Pred[i+1]))\n",
    "    Qrom.append(np.cov(errPred[i+1].astype(float)))  # Covariance of error\n",
    "    idx.append(i+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
